[TOC]
# 操作系统
------
## Content
- 概论
- 操作系统内核
- 并发

------
## 概论
操作系统的基本动机：更快更好地服务更多应用  
基本方法：Building Abstractions（抽象）    
**管理软硬件资源，为程序提供服务** 的程序  
以API的形式管理共享资源（产生 进程、地址空间 等概念）   

切入的关键：什么是资源，这些资源是“怎么样的”？  

---
### 应用视角的操作系统
程序的本质是状态机（寄存器和内存的状态） （拥有严格数学定义的）    

程序的退出是由OS实现的（把系统调用参数放到寄存器中，执行syscall，操作系统接管程序）  
操作系统可以任意改变程序的状态

*关闭计算机是由OS和硬件（电源管理接口）、计算机固件（如BIOS、UEFI）交互协作实现的*   

操作系统提供令应用程序舒适的抽象（对象+API）  

<br>

---
### 硬件视角的操作系统
计算机系统中的一切都是状态机  
RESET内部状态，执行firmware代码（固件）（配置计算机系统、加载OS）  

操作系统就是一个运行在计算机硬件上的程序  

<br>

---
### 数学视角的操作系统
程序是一种“数学严格”的对象（状态 + 迁移函数）  
*编程时，应把需要保证（证明）的性质写成 assertions*   

操作系统是状态机的管理者（状态机的容器），同时也是一个状态机   

- 状态：多个“应用程序”状态机
- 初始状态：仅有一个“main”状态机
- 迁移：选择一个状态机执行一步
- 调度：状态机选择的不确定性
- I/O：系统外的输入不确定性

操作系统建模状态图
证明一个程序的正确性（尤其在并发场景下）：在程序状态图上做BFS  

<br>

------
## 操作系统内核
应用连接硬件设备的桥梁（应用程序只与内核交互）  
现代操作系统内核一般会提供 4 个基本能力：
- 进程调度：管理进程、线程，决定哪个进程、线程使用 CPU
- 内存管理：决定内存的分配和回收
- 硬件通信：管理硬件设备，为进程与硬件设备之间提供通信能力
- 提供系统调用：如果应用程序要运行更高权限运行的服务，就需要系统调用；（用户程序与操作系统之间的接口）

内存划分为内核空间与用户空间  

内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后，CPU 会中断当前在执行的用户程序，跳转到中断处理程序（开始执行内核程序）。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作  

<br>

------
## 并发
操作系统上允许运行多个程序   

在 Linux 内核中，进程和线程都是用 `task_struct` 结构体表示的，区别在于线程的 `task_struct` 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等  
一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多的事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是 `task_struct`（OS内核里调度的对象）  

并发控制：  
- 互斥锁实现原子性
- 条件变量/信号量实现顺序同步

<br>

### 多处理器编程
多线程编程模型：多个共享内存的状态机  
- C语言状态机的多个线程：共享全局变量、独立的栈帧列表
- 汇编语言状态机的多个线程：共享的地址空间、独立的寄存器（SP指向不同的内存位置）

线程之间有共享内存  
线程具有独立的堆栈   

状态迁移：任意选择一个线程执行一步  

OS会自动把线程放在不同处理器上   
线程可能在不同 CPU 核心来回切换执行   
多核CPU的L3 Cache是核心之间共享的，L1、L2 Cache是每个核心独有的  

不同的处理器上，“对全局状态的观测是相对的”   
不同处理器可能看到不同的内存镜像（每个线程对应不同的副本）  

<br>

---
### 并发控制——互斥
多处理器和并发执行推翻了顺序执行的基本假设  
如何实现CPU的原子性？（“原子的”状态迁移）  

中断是每一个处理器独享的  

`lock()`、`unlock()` 实现互斥  
通过硬件实现的原子指令  
*为每一个重要的资源设置一个锁*  

CPU状态迁移：从PC取指令执行或响应中断信号（中断打开时）  

（多处理器）操作系统内核中的互斥：上锁 / 解锁前后中断状态不变（关闭当前CPU的中断）  
CPU中维护对“关闭中断”的计数，以及关闭中断前的中断状态  

自旋锁随着线程数（CPU数）的上升，性能不断下降  
一般只用于OS内核的并发数据结构（短临界区）（一般不发生拥堵）   

Read-Copy-Update方法：  
许多操作系统内核对象具有“read-mostly”特点  
可以减少读写一致性的保证 —— copy on write（相对于全局读写顺序上，允许部分读到旧数据）  
<b>改写 = 复制</b>   
当所有CPU都完成了一次线程切换（不会再有访问都旧版本），可以回收旧版本  

<br>

应用程序互斥的性能问题：
- 争抢锁的处理器越多，利用率越低
- 如果临界区较长，不如把处理器让给其他线程
- 应用程序不能关中断，可能发生当前持有某一锁的线程被切换

如何实现“让锁”？  
- 把锁的实现交给操作系统 （利用<b>操作系统管理状态机的能力</b> 标记不同状态机的“需求状态”）
- `syscall(SYSCALL_lock, &lk)`如果获得锁失败，就切换到其他线程
- `syscall(SYSCALL_unlock, &lk)`释放锁，如果有线程等待就唤醒

问题：如何保证在释放锁时，一个刚刚获得锁失败的线程能够被正确唤醒？  

<br>

---
### 并发控制——同步
多个线程协同完成任务（调控代码执行的实现）   
*控制并发，使得 “两个或两个以上随时间变化的量在变化过程中保持一定的相对关系”*  

同步问题的关键在于 <b>“同步的条件”</b>  
（状态机的共享状态达到某个条件）  

抽象成 “生产者-消费者问题”  
producer和consumer共享一个缓冲区  

条件变量：把条件用一个变量来替代，条件不满足时等待，条件满足时唤醒  
（把原本每个线程上都做的检查统一交给内核处理）  
使用<b>while循环（自旋）</b>和<b>broadcast</b>：
- 总是在唤醒时再次检查同步条件
- 总是唤醒所有潜在的可能被唤醒的线程（通知“全局状态发生了变更”）

```c++
mutex_lock(&mutex); // 互斥锁保证条件变量在退出循环时还成立
while(!COND)
{
    wait(&cv, &mutex);
}
assert(cond);
...
mutex_unlock(&mutex);
```  
`wait(&cv, &mutex)` 中实现释放锁、睡眠  


将总计算任务分解为若干步，分析每一步之间的依赖关系，构建<b>有向无环图</b>   
调度器（生产者）分配任务给worker（消费者）  
为每一个节点设置一个条件变量  

<br>

如何实现release-acquire？（维护 “happens-before” 关系）  
信号量：可以在不同线程中进行获取和释放（条件为`count > 0`的条件变量）   
信号量 API：
```c++
void P(sem_t *sem)
{
    atomic {
        wait_until(sem->count > 0) {
            sem->count--;
        }
    }
}
void V(sem_t *sem)
{
    atomic {
        sem->count++;
    }
}
```
mutex 可以视为 n=1 的信号量
每个信号量都有一个计数器 <b>管理计数型资源</b>   
当能用一个整数表达同步条件时，就可以使用信号量实现  

*使用两个信号量`empty`（初始为 n）和 `fill`（初始为 0）描述“生产者-消费者”*   

<br>

---
### 协程
和线程概念相同（独立堆栈，共享内存）  
但“一直执行”（不会被OS打断），直到`yield()`主动放弃处理器（`yield()`只需保存/恢复 non-volatile的寄存器，而线程切换需要保存/恢复全部寄存器）   

<br>

---
### 死锁
必要条件：  
- 1、Mutual-exclusion 一个口袋一个球，得到才能继续
- 2、Wait-for 得到球的人想要更多的球
- 3、No-preemption 不能抢走其他人的球
- 4、Circular-chain 循环等待

打破任何一个条件，就能够避免死锁  

在实际系统中避免死锁的方法：Lock ordering 给锁编号，按顺序获得锁  

<br>

---
### 数据竞争
有两个不同线程同时访问同一内存，且至少有一个是写操作  
系统状态的结果取决于谁更快  

*用互斥锁保护共享数据 消除数据竞争*  

栈区也是共享内存  

<br>

------
## 虚拟化
进程的状态：内存 + 寄存器  

<br>

### 创建进程 `fork()`
返回一个`pid`，创建当前进程状态机的完整副本（内存、寄存器现场），并构成父子关系（最终形成“进程树”）   

<br>

### 运行exe文件 
Linux中“执行文件的系统调用”：  
`int execve(const char *filename, char * const argv[], char * const envp[])`   
把当前进程重置为一个可执行文件描述状态机的<b>初始状态</b>；同时，允许对新状态机设置参数（argv）和环境变量（envp）   

一般情况下，子进程继承环境变量   

`PATH`环境变量进行路径查找  

<br>

### 退出进程
`_exit(int status)`：摧毁状态机   
多线程程序的情况？（`exit_group`）  

<br>

------
## 虚拟内存
为每个进程分配<b>独立的一套虚拟地址</b>，从而可以**把进程所使用的地址隔离开来**  
使得进程的运行内存可以超过物理内存大小  
操作系统提供一种机制，**管理不同进程的虚拟地址和不同内存的物理地址的映射关系**  
通过 CPU 芯片中的内存管理单元（MMU）中的映射关系实现  
进程的寄存器状态中，保存进程虚拟内存根节点（一级页表），并维护一个缓存区域  

每个虚拟内存中的 内核地址，关联相同的物理内存  

内核管理的数据结构上，如何实现高效的内存映射？  

<br>

---
### 内存分段
不同段具有不同的属性  
`（段选择子，段内偏移量）`   
段选择子：保存在 段寄存器 中，包含 段号 与 特权等标志位；
段号：用作 段表 的索引  
段表：保存 段的基地址、段的界限和特权等级  

问题：*产生内存碎片 & （整理碎片空间时）与磁盘进行内存交换效率低*  

<br>

### 内存分页
尽可能减少内存碎片与内存交换开销  
**把整个虚拟和物理内存空间切成固定尺寸的大小**  
`（页号，页内偏移）`   
 
<b>页表存放在内存中，覆盖全部虚拟地址空间</b>   
页号：用作 页表 的索引  
页表：包含物理页每页所在 物理内存的基地址  
每个进程都有自己的虚拟地址空间的，即都有自己的页表  

<b>缺页异常</b>：进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，*进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行*  

页与页之间是紧密排列的，不会有外部碎片  

内存空间不够时，OS会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉（暂时写在硬盘swap分区上 换出（Swap Out）；一旦需要的时候，再加载 换入（Swap In））  

- 文件页：内核缓存的磁盘数据和文件数据；回收干净页（没有修改）的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存  
- 匿名页：没有实际载体，如栈区、堆区数据；回收时通过Swap机制写到磁盘上

分页使得在加载程序时，不再需要一次性都把程序加载到物理内存中，可以只 **在程序运行中需要用到对应虚拟内存页中的指令和数据时，再加载到物理内存**   

<b>多级页表</b>：将页表再分页，一级页表覆盖全部虚拟地址空间，在实际需要时才创建下一级页表的相应页面  
每个进程都有 4GB 的虚拟地址空间，但大多数程序使用空间远未达到 4GB；会存在部分对应的页表项都是空的，根本没有实际分配   
*对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，OS会将该页面换出到硬盘*   

<b>页表缓存 TLB</b>：存放程序最常访问的页表项的 Cache  

<br>

### 段页式内存管理
先将程序划分为多个有逻辑意义的段，对分段划分出来的连续空间，再划分固定大小的页  
`（段号、段内页号、页内偏移）`   

<br>

---
### 进程地址空间
进程地址空间：带访问权限的一段段内存`[start, end)`（虚拟内存），且可能对应设备/文件  

通过 Memory Map系统调用 管理地址空间：增加/删除/修改一段可访问的内存    

malloc(...)：  
- 小于128KB时，调用`brk()`移动堆顶指针分配内存（此类内存释放后不会马上归还给OS，而是先缓存在 malloc 的内存池里）
- 大于128KB时，调用`mmap()`在文件映射区域分配内存  

64位系统中，用户态虚拟内存空间与内核态虚拟内存空间分别占用 128T，其中低128T 分配给用户态虚拟内存空间，高 128T 分配给内核态虚拟内存空间  

调用 `fork()` 函数创建进程的时候，表示进程地址空间的 `mm_struct` 结构会随着进程描述符 `task_struct` 的创建而创建；同时，父进程的资源会拷贝填充 `task_struct` 信息（包括了 `mm_struct`）  
（Copy-On-Write）子进程继承的页表一开始与父进程页表指向相同的物理内存，但标记为只读；当要写入时，触发页错误，并由操作系统分配新的物理页、更新进程的页表条目  

内核线程和用户线程的区别就是内核线程没有相关的内存描述符 `mm_struct`；内核线程对应的 `task_struct` 结构中的 `mm` 为 `Null`；<b>内核线程之间调度是不涉及地址空间切换的，内核态虚拟内存空间是所有进程共享的</b>   
可以将调度之前的上一个用户态进程的虚拟内存空间 `mm_struct` 直接赋值给内核线程  

`mm_struct`内通过一个 `vm_area_struct` 结构的 <b>双向链表</b> 将虚拟内存空间中的这些 虚拟内存区域 VMA（段） 串联起来，实现高效遍历；再通 <b>红黑树</b> 实现高效查找  
在每个虚拟内存区域 VMA 中又通过 `vm_mm` 指针指向所属的虚拟内存空间 `mm_struct`   

<br>

---
## 物理内存管理
内核以页为基本单位对物理内存进行管理（将物理内存划分为一页一页的内存块），一页大小的内存块在内核中用 `struct page` 结构体（封装了每页内存块的状态信息）进行管理  

<br>

### 动态热插拔支持
（难点主要在于物理内存拔出的过程）  
当 mem_section offline 时, 内核会**把这部分内存隔离开, 使得该部分内存不可再被使用, 然后再把 mem_section 中已经分配的内存页迁移到其他 mem_section 的内存上**    
迁移意味着物理内存地址的变化；迁移后的物理页映射的虚拟内存地址是能变化，如何保证？   
- 用户态空间：内核通过修改相应页表项实现
- 内核态空间：直接映射区中的物理页的虚拟地址会随着物理内存地址变动而变动；将内存按照物理页是否可迁移，划分为 <b>不可迁移页、可回收页、可迁移页</b>；在可能会被拔出的内存中，只分配那些可迁移的内存页

<br>

### 非一致性内存访问 NUMA架构
所有CPU共用同一个内存容易使总线成为性能瓶颈  
内存被划分成了一个一个的内存节点（NUMA节点）；每个 CPU 都有属于自己的本地内存节点，CPU 访问自己的本地内存不需要经过总线；CPU 之间通过 QPI（Intel QuickPath Interconnect）点对点完成互联   

通过相应接口（状态）为进程设置不同的内存分配策略  

<br>

------
## 操作系统对象管理
- 进程
- 内存
- 文件（有 “名字” 的对象；字节流 （终端） 或字节序列）
  - 文件描述符：指向操作系统对象的“指针”
- 进程间通信
  - 管道：一个特殊的“文件”（流），由读者/写者共享

<br>

### 进程
三个基本状态：
- 运行状态（Running）：占用 CPU
- 就绪状态（Ready）：可运行，但其他进程处于运行状态
- 阻塞状态（Blocked）：正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行

当进程已经运行完成或出错时，会被 OS 作结束状态处理  
通常会把阻塞状态的进程的物理内存空间换出到硬盘（挂起），等需要再次运行的时候，再从硬盘换入到物理内存   

进程控制块 PCB：
- 进程描述信息：进程标识符（标识各个进程，每个进程都有一个唯一的标识符）、用户标识符（标识进程归属的用户，主要为共享和保护服务）
- 进程控制和管理信息：状态、优先级等
- 资源分配清单：有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息
- CPU 相关信息

通常通过<b>链表</b>组织各 PCB，**把具有相同状态的进程链在一起，组成各种队列**     

<br>

### Shell —— 操作系统的外壳
将操作系统与I/O设备连接起来  

基本功能：启动系统中的应用程序  
基于文本替换的快速工具流搭建  

<br>

### libc —— 系统调用基础上的C标准库  
- 提供对基础编程机制的抽象
- 提供对系统调用与环境的抽象
  - 所有API都可能失败；每个线程都有自己的`errno` 
  - 实现C代码和二进制代码（汇编）之间的联系（*操作系统有一个 “初始状态”，libc 调用 main 前还会继续初始化这个 “初始状态”；进程堆栈初始化时 保存状态：`argc`、`char *argv[]`、`char *envp[]`*）（System V ABI）
- 动态内存管理（操作系统本身不支持分配小段内存）
  - `malloc(...)`、`free()`在大区间 `[L, R)` 维护互不相交的区间集合

<br>

### InitialRAMFS —— 初始文件系统
系统启动后，fireware将操作系统加载到内存，把控制权交给 `init`进程   
`InitRAMFS`：`init`进程所见初始的“小世界”（系统内初始的对象）  
由`init`执行一系列系统调用 构建出完整的操作系统环境（各种系统内的对象） 
调用`switch_root`命令（底层为`pivot_root`系统调用，要求`pid==1`）将根文件系统和控制权移交给另一个程序（如 `systemd`）   
`systemd` 通过 `mount` 系统调用配置文件系统  

<br>

### 可执行文件
链接和加载中的核心概念：代码、符号、重定位  

可执行文件本质上是一个描述了初始状态的数据结构  

静态ELF加载器：将<b>多段字节序列</b>复制到地址空间中，并分别赋予 可读/可写/可执行 权限；然后跳转到指定的entry（默认为`_start`）执行  
ELF磁盘文件中的 Section 会在进程运行之前加载到内存中并映射到内存中的 Segment（内存映射）；通常是多个 Section 映射到一个 Segment  

<br>

### 动态链接
多个程序使用同一个库时，不需要往内存里加载多份副本   

编译器生成位置无关代码（PIC，所有跳转都是相对的）；目标文件包含符号表，记录所有定义和引用的符号   
链接器负责将多个目标文件链接成一个可执行文件；主要任务是符号解析和地址分配   

动态链接器额外维护一个表，符号解析（函数调用）对应查表过程  
加载 = mmap（将共享库文件映射到进程的虚拟地址空间中），但函数调用时需要额外一次查表  
链接时，收集所有符号，“生成”符号信息和相关代码  

每个进程加载动态库时，尽管库文件本身是共享的，但每个进程看到的是它们自己虚拟地址空间中的映射  

重定向的问题：跳转指令数的位数限制？共享库加载到了哪里？如何访问编译单元外的变量？  
全部采用直接跳转。对于动态链接，跳转到PLT生成的跳转指令，再二次跳转到相应位置  

<br>

------
## 系统调用指令
<b>对操作系统的函数调用</b>  
保护寄存器现场、跳转到操作系统代码  
（软中断的一种）   
在另一个栈中执行，执行时可以直接访问IO设备和内核数据结构，结束后执行`sysret`  

x86中CR3寄存器指向页基地址（标志如何构建出“虚拟环境”）  

<br>

## 调度
操作系统为每一个 thread 维护一个数据结构，并维护其现场（寄存器状态）  
操作系统可以选择任何一个寄存器现场放到CPU上执行   

当前执行的状态对应一个`context`   
```c
Context *on_interrupt(Event ev, Context *ctx)
{
  // save context
  current->context = *ctx;

  // thread schedule
  current = current->next;

  // restore current thread's context
  return &current->context;
}
```

进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源  
