[TOC]
# 操作系统
------
## Content
- 概论
- 操作系统内核
- 并发

------
## 概论
操作系统的基本动机：更快更好地服务更多应用  
基本方法：Building Abstractions（抽象）    
**管理软硬件资源，为程序提供服务** 的程序  
以API的形式管理共享资源（产生 进程、地址空间 等概念）   

切入的关键：什么是资源，这些资源是“怎么样的”？  

---
### 应用视角的操作系统
程序的本质是状态机（寄存器和内存的状态） （拥有严格数学定义的）    

程序的退出是由OS实现的（把系统调用参数放到寄存器中，执行syscall，操作系统接管程序）  
操作系统可以任意改变程序的状态

*关闭计算机是由OS和硬件（电源管理接口）、计算机固件（如BIOS、UEFI）交互协作实现的*   

操作系统提供令应用程序舒适的抽象（对象+API）  

<br>

---
### 硬件视角的操作系统
计算机系统中的一切都是状态机  
RESET内部状态，执行firmware代码（固件）（配置计算机系统、加载OS）  

操作系统就是一个运行在计算机硬件上的程序  

<br>

---
### 数学视角的操作系统
程序是一种“数学严格”的对象（状态 + 迁移函数）  
*编程时，应把需要保证（证明）的性质写成 assertions*   

操作系统是状态机的管理者（状态机的容器），同时也是一个状态机   

- 状态：多个“应用程序”状态机
- 初始状态：仅有一个“main”状态机
- 迁移：选择一个状态机执行一步
- 调度：状态机选择的不确定性
- I/O：系统外的输入不确定性

操作系统建模状态图
证明一个程序的正确性（尤其在并发场景下）：在程序状态图上做BFS  

<br>

------
## 操作系统内核
应用连接硬件设备的桥梁（应用程序只与内核交互）  
现代操作系统内核一般会提供 4 个基本能力：
- 进程调度：管理进程、线程，决定哪个进程、线程使用 CPU
- 内存管理：决定内存的分配和回收
- 硬件通信：管理硬件设备，为进程与硬件设备之间提供通信能力
- 提供系统调用：如果应用程序要运行更高权限运行的服务，就需要系统调用；（用户程序与操作系统之间的接口）

内存划分为内核空间与用户空间  

内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后，CPU 会中断当前在执行的用户程序，跳转到中断处理程序（开始执行内核程序）。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作  

<br>

------
## 并发
操作系统上允许运行多个程序   

在 Linux 内核中，进程和线程都是用 `task_struct` 结构体表示的，区别在于线程的 `task_struct` 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等  
一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多的事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是 `task_struct`（OS内核里调度的对象）  

并发控制：  
- 互斥锁实现原子性
- 条件变量/信号量实现顺序同步

<br>

### 多处理器编程
多线程编程模型：多个共享内存的状态机  
- C语言状态机的多个线程：共享全局变量、独立的栈帧列表
- 汇编语言状态机的多个线程：共享的地址空间、独立的寄存器（SP指向不同的内存位置）

线程之间有共享内存  
线程具有独立的堆栈   

状态迁移：任意选择一个线程执行一步  

OS会自动把线程放在不同处理器上   
线程可能在不同 CPU 核心来回切换执行   
多核CPU的L3 Cache是核心之间共享的，L1、L2 Cache是每个核心独有的  

不同的处理器上，“对全局状态的观测是相对的”   
不同处理器可能看到不同的内存镜像（每个线程对应不同的副本）  

<br>

---
### 并发控制——互斥
多处理器和并发执行推翻了顺序执行的基本假设  
如何实现CPU的原子性？（“原子的”状态迁移）  

中断是每一个处理器独享的  

`lock()`、`unlock()` 实现互斥  
通过硬件实现的原子指令  
*为每一个重要的资源设置一个锁*  

CPU状态迁移：从PC取指令执行或响应中断信号（中断打开时）  

（多处理器）操作系统内核中的互斥：上锁 / 解锁前后中断状态不变（关闭当前CPU的中断）  
CPU中维护对“关闭中断”的计数，以及关闭中断前的中断状态  

自旋锁随着线程数（CPU数）的上升，性能不断下降  
一般只用于OS内核的并发数据结构（短临界区）（一般不发生拥堵）   

Read-Copy-Update方法：  
许多操作系统内核对象具有“read-mostly”特点  
可以减少读写一致性的保证 —— copy on write（相对于全局读写顺序上，允许部分读到旧数据）  
<b>改写 = 复制</b>   
当所有CPU都完成了一次线程切换（不会再有访问都旧版本），可以回收旧版本  

<br>

应用程序互斥的性能问题：
- 争抢锁的处理器越多，利用率越低
- 如果临界区较长，不如把处理器让给其他线程
- 应用程序不能关中断，可能发生当前持有某一锁的线程被切换

如何实现“让锁”？  
- 把锁的实现交给操作系统 （利用<b>操作系统管理状态机的能力</b> 标记不同状态机的“需求状态”）
- `syscall(SYSCALL_lock, &lk)`如果获得锁失败，就切换到其他线程
- `syscall(SYSCALL_unlock, &lk)`释放锁，如果有线程等待就唤醒

问题：如何保证在释放锁时，一个刚刚获得锁失败的线程能够被正确唤醒？  

<br>

---
### 并发控制——同步
多个线程协同完成任务（调控代码执行的实现）   
*控制并发，使得 “两个或两个以上随时间变化的量在变化过程中保持一定的相对关系”*  

同步问题的关键在于 <b>“同步的条件”</b>  
（状态机的共享状态达到某个条件）  

抽象成 “生产者-消费者问题”  
producer和consumer共享一个缓冲区  

条件变量：把条件用一个变量来替代，条件不满足时等待，条件满足时唤醒  
（把原本每个线程上都做的检查统一交给内核处理）  
使用<b>while循环（自旋）</b>和<b>broadcast</b>：
- 总是在唤醒时再次检查同步条件
- 总是唤醒所有潜在的可能被唤醒的线程（通知“全局状态发生了变更”）

```c++
mutex_lock(&mutex); // 互斥锁保证条件变量在退出循环时还成立
while(!COND)
{
    wait(&cv, &mutex);
}
assert(cond);
...
mutex_unlock(&mutex);
```  
`wait(&cv, &mutex)` 中实现释放锁、睡眠  


将总计算任务分解为若干步，分析每一步之间的依赖关系，构建<b>有向无环图</b>   
调度器（生产者）分配任务给worker（消费者）  
为每一个节点设置一个条件变量  

<br>

如何实现release-acquire？（维护 “happens-before” 关系）  
信号量：可以在不同线程中进行获取和释放（条件为`count > 0`的条件变量）   
信号量 API：
```c++
void P(sem_t *sem)
{
    atomic {
        wait_until(sem->count > 0) {
            sem->count--;
        }
    }
}
void V(sem_t *sem)
{
    atomic {
        sem->count++;
    }
}
```
mutex 可以视为 n=1 的信号量
每个信号量都有一个计数器 <b>管理计数型资源</b>   
当能用一个整数表达同步条件时，就可以使用信号量实现  

*使用两个信号量`empty`（初始为 n）和 `fill`（初始为 0）描述“生产者-消费者”*   

<br>

---
### 协程
和线程概念相同（独立堆栈，共享内存）  
但“一直执行”（不会被OS打断），直到`yield()`主动放弃处理器（`yield()`只需保存/恢复 non-volatile的寄存器，而线程切换需要保存/恢复全部寄存器）   

<br>

---
### 死锁
必要条件：  
- 1、Mutual-exclusion 一个口袋一个球，得到才能继续
- 2、Wait-for 得到球的人想要更多的球
- 3、No-preemption 不能抢走其他人的球
- 4、Circular-chain 循环等待

打破任何一个条件，就能够避免死锁  

在实际系统中避免死锁的方法：Lock ordering 给锁编号，按顺序获得锁  

<br>

---
### 数据竞争
有两个不同线程同时访问同一内存，且至少有一个是写操作  
系统状态的结果取决于谁更快  

*用互斥锁保护共享数据 消除数据竞争*  

栈区也是共享内存  

<br>

------
## 虚拟化

### 创建进程 `fork()`
返回一个`pid`，创建当前进程状态机的完整副本（内存、寄存器现场），并构成父子关系（最终形成“进程树”）   


------
### 虚拟内存
为每个进程分配<b>独立的一套虚拟地址</b>，从而可以把进程所使用的地址隔离开来  
操作系统提供一种机制，**管理不同进程的虚拟地址和不同内存的物理地址的映射关系**  
通过 CPU 芯片中的内存管理单元（MMU）中的映射关系实现  

---
### 内存分段
不同段具有不同的属性  
`（段选择子，段内偏移量）`   
段选择子：保存在 段寄存器 中，包含 段号 与 特权等标志位；
段号：用作 段表 的索引  
段表：保存 段的基地址、段的界限和特权等级  

问题：*产生内存碎片 & （整理碎片空间时）与磁盘进行内存交换效率低*  

<br>

### 内存分页
尽可能减少内存碎片与内存交换开销  
**把整个虚拟和物理内存空间切成固定尺寸的大小**  
`（页号，页内偏移）`   

页表存放在内存中  
页号：用作 页表 的索引  
页表：包含物理页每页所在 物理内存的基地址  
每个进程都有自己的虚拟地址空间的，即都有自己的页表  

<b>缺页异常</b>：进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，*进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行*  

页与页之间是紧密排列的，不会有外部碎片  

内存空间不够时，OS会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉（暂时写在硬盘上 换出（Swap Out）；一旦需要的时候，再加载 换入（Swap In））  
分页使得在加载程序时，不再需要一次性都把程序加载到物理内存中，可以只 **在程序运行中需要用到对应虚拟内存页中的指令和数据时，再加载到物理内存**  
