[TOC]
# Content
- BASIC
  - 应用层
  - 传输层
  - 网络层
- 消息队列 
- 流量分发 & 负载均衡

------
# 计算机网络

---
## 应用层
如 HTTP、FTP、Telnet、DNS、SMTP等  
只需要专注于 <b>为用户提供应用功能</b>，不用去关心数据是如何传输的  
应用层工作在操作系统中的用户态  

URL 对应于“请求某一服务器的某一资源”  
浏览器解析 URL 并生成 HTTP 消息后，委托操作系统将消息发送给 Web 服务器  

DNS服务器保存 Web 服务器域名与 IP 的对应关系  

<br>

---
### HTTP
超文本传输协议 HyperText Transfer Protocol  

HTTP/1.1：
- 持久链接（相较1.0）：可以实现管道传输（可在同一个 TCP 连接里面，客户端可以发起多个请求，不用等待响应后再发送）；但服务器是按请求的顺序响应的，服务器响应慢时会导致客户端一直请求不到数据（队头阻塞）
- 只能压缩`body`部分，首部信息越多延迟越大，且每次互相发送相同的首部造成的浪费较多
- 无状态：服务器不会去记忆 HTTP 的状态    
- 没有请求优先级控制
- 请求只能从客户端开始，服务器只能被动响应

Cookie：通过 在请求和响应报文中写入 Cookie 信息 来**控制客户端的状态**  

HTTP为明文传输：不安全，且无法验证身份  
HTTPS：在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，实现了信息加密和校验机制（是否被修改）、身份证书  
TLS握手过程取决于 密钥交换算法  

缓存：客户端把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，形成<b>映射关系</b>，并设置一个<b>过期时间</b>；过期后发送头部带有资源摘要的请求  

HTTP/2：  
- 基于HTTPS；先进行TCP握手，再进行TLS握手
- 头部压缩：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号；不发送同样字段，只发送索引号
- 报文采用二进制格式，以frame为最小单位（分为 headers frame 和 data frame）
- 并发传输：多个 Stream 复用在一条 TCP 连接
- 服务器推送：服务器可以主动发送消息
- 基于TCP，由于“TCP 层必须保证收到的字节数据是完整且连续的，内核才会将缓冲区里的数据返回给 HTTP 应用”，还是可能发生队头阻塞

HTTP/3:  
- 基于UDP，解决队头阻塞问题
- 采用基于 UDP 的 QUIC 协议，实现类似 TCP 的可靠传输（QUIC上的多个流之间没有相互依赖，当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题）
- QUIC握手只需要 1 RTT（用于确认双方的「连接 ID」）（QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”）
- 在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0 RTT
- 更低的连接迁移成本（只通过连接 ID 来标记通信的两个端点）

<br>

如何减少HTTP请求次数？  
- 减少（资源迁移引起的）重定向请求次数：重定向的工作交由代理服务器完成
- 合并请求：把多个访问小文件的请求合并成一个大的请求
- 延迟发送请求：只获取当前用户所看到的页面资源

HTTP轮询：  
- 不断轮询
- 长轮询（设置较大的超时时长限制）

<br>

---
### RPC
远程过程调用 Remote Procedure Call  
像调用本地方法那样去调用远端的服务方法  
特点：面向动作、请求响应模式、同步、对象级/函数级通信  

服务发现：一般通过专门的中间服务（如 Consul 或者 Etcd）保存服务名和 IP 信息  

RPC协议一般会维护一个 <b>连接池</b>  
*请求量大时，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来*   

一般对于客户端来说，RPC是一种同步的远程服务调用技术（而MQ是异步的）  
RPC调用步骤：  
- 1、建立通信：消费者要想调用提供者的方法，首先要和提供者建立通信连接；主要是通过 客户端和服务器之间 建立TCP连接 实现的
- 2、服务寻址：确定提供者的IP、端口号以及方法的名称
- 3、网络传输：将调用方法和参数的数据进行序列化传输给提供者，提供者将接收到的参数进行反序列化操作后执行方法
- 4、服务调用：提供者进行本地调用后得到了返回值，提供者将返回值进行序列化操作后，再通过网络传输将二进制数据发送回给消费者

<br>

---
### WebSocket
利用 TCP 全双工（同一时间里，双方都可以主动向对方发送数据）  

<br>

------
## 传输层
接收方凭借传输层的报文中携带的 端口号 识别出该报文是发送给哪个应用（进程）   

序列号、确认应答号（下一个期望收到的序列号）用于解决丢包问题  
校验和用于检测包是否受损  

`MSL`：定义一个报文在网络中的最长生存时间（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃）  

### TCP & UDP
TCP的机制背后是<b>通过一个个数据结构来实现的逻辑</b>。而为了实现这套逻辑，操作系统内核需要在两端代码里维护一套复杂的<b>状态机</b>（三次握手，四次挥手，RST，closing等异常处理机制），<b>这套状态机其实就是所谓的"连接"</b>。 &emsp; 而UDP不需要状态机   
（实现 **流量控制、超时重传、拥塞控制** 等 特性）  

一条 TCP 连接通过四元组（源 IP、源端口、目的 IP、目的端口）确定  
**面向连接、可靠、基于字节流**   

UDP本质是 内核提供的一个最小网络传输功能（在应用层添加可靠性保障）  

在传一个大的数据包时，TCP内部根据 MSS 的大小（除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度）分段，丢包只需重传MSS分片；而UDP本身并不会分段，数据过大时，到了IP层进行分片，丢包需要重传整个数据包。  

TCP 面向字节流（不能认为一个用户消息对应一个 TCP 报文），UDP 面向报文（UDP 不会对消息进行拆分）  
相比 TCP 一对一，UDP 支持一对一、一对多、多对多的交互通信  

TCP粘包问题（无法确定在一个报文中的两个消息怎么划分）：使用特殊字符作为边界 或 自定义消息结构（固定长度包头 + 数据）

<br>

---
### TCP 三次握手与四次挥手
服务器的内核实际上为每个 TCP 的 Socket 维护了 <b>两个队列</b>：  
- TCP 半连接队列：还没完全建立三次握手的连接（此时服务端处于 `syn_rcvd` 状态）
- TCP 全连接队列:完成了三次握手,已经建立连接的队列（此时服务端处于 `established` 状态）

三次握手：  
1 客户端请求连接`SYN`、2 服务端回复同意`SYN + ACK`、3 客户端回复收到同意并开始正式发送数据（第三次握手可以携带数据）`ACK`  
*防止已经失效的连接请求报文突然又传送到了服务器 （阻止重复历史连接的初始化）*  
（若两次握手可能导致 因超时而重复发送的1带来了多次的连接）  

四次挥手：  
1 客户端“我发完了”（但还可以接收数据）`FIN` 、2 服务端回复收到（此时服务端可能仍有数据未发送）`ACK` 、3 服务端“我发完了”`FIN` 、4 客户端回复收到`ACK`    
关键在于 服务端通常需要等待 数据的发送和处理 全部完成   
服务端进程主动调用 `close()` 函数来触发服务端发送`FIN`报文  

`ACK` 报文不会重传（需依靠前序报文的超时重传）  

**TCP 的连接信息是由内核维护的。** 当服务端的进程崩溃时，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 `FIN`报文，后续的挥手过程也都是在内核完成，并不需要进程的参与；即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程  

<br>

---
### TIME_WAIT
主动发起关闭连接的一方，才会有 TIME-WAIT 状态
- 防止历史连接中的数据，被后面相同四元组的连接错误接收（保证再出现的数据包一定都是新建立连接所产生的）
- 保证「被动关闭连接」的一方，能被正确的关闭

从主动方接收到`FIN`后发送`ACK`开始重置计时   
等待时间一般设置为`2MSL`（允许报文丢失一次） （*网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间*）  

服务器出现大量 TIME_WAIT 状态时，说明服务器主动断开了很多 TCP 连接  
- HTTP 没有使用长连接（在请求的header中添加 Keep-Alive）
- HTTP 长连接超时
- HTTP 长连接的请求数量达到上限

<br>

---
### TCP 滑动窗口
提升了发送速度，同时兼顾了接收方的处理能力  
让发送方根据接收方的实际接收能力控制发送的数据量  

报文存放在OS的内核缓冲区  
发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了 “已发送未确认” 的报文的上限  
发送缓冲区不能超过 带宽时延积（RTT * 带宽）  

接收方把 当前接收窗口可接收的大小 放在 TCP 报文头部中的窗口字段  

发送缓冲区是自行调节的；当数据被确认后，且没有新的数据要发送，就会把发送缓冲区的内存释放掉  
接收缓冲区可以根据系统空闲内存的大小来调节接收窗口  

在发送端调用`send`，只是从应用程序拷贝到操作系统的内核协议栈中，还没有真正地发出  

<br>

------
## 网络层
寻路、路由；负责将数据从一个设备传输到另一个设备（路径和节点选择）  

### IP协议
将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文   

IP 地址分成两种意义：（通过子网掩码）
- 网络号：负责标识该 IP 地址是属于哪个「子网」的；
- 主机号：负责标识同一「子网」下的不同主机；


------
# 消息队列 MQ
特点：面向数据、生产者与消费者、有缓冲节点、异步、系统级/模块级通信  
主要应用场景：延时任务、应用解耦（MQ负责通知，各节点对应于消息作不同操作）、流量削峰、日志处理（日志处理应用订阅并削峰消息队列中的日志数据，避免短期要处理大量日志）、异步消息通讯（提供系统整体吞吐量）

消息的发送者和消费者不再直接交互，而是通过中间件间接交互，实现了解耦  
发送者并不关心谁来消费信息（常常不止一个消费者）；且各个消费者可以从不同的角度入手处理消息，处理结果也不用返回给发送者    

- 点对点模式：一个生产者发送的每一个消息，都只有一个消费者消费；允许多个生产者向同一个队列里发送消息，但是只有一个消费者能拿到数据
- 发布订阅模式：消息会发送到所有订阅了此队列的消费者；一个队列为一个“主题”

---
## Kafka
利用了「零拷贝」技术，大幅提升了 I/O 吞吐率（只需要 2 次上下文切换和数据拷贝次数）  
没有在内存层面拷贝数据（全程没有通过 CPU 来搬运数据，所有数据通过 DMA 来进行传输）　　

------
# 流量分发 & 负载均衡
如何分配客户端的请求？  

------
### 一致性哈希
避免分布式系统在扩容或者缩容（节点数量变化）时，由于哈希值变化（映射关系改变），发生过多的数据迁移  

一致性哈希：将「存储节点」和「数据」都映射到一个首尾相连的哈希环上  
在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点   

一致性哈希算法虽然减少了数据迁移量，但存在节点分布不均匀的问题  
解决办法：加入虚拟节点；不再将真实节点映射到哈希环上，而是**将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点**（两层映射关系）  

<br>

---
## Nginx
