# 计算机网络
[TOC]
# Content
- BASIC
  - 应用层
  - 传输层
  - 网络层
- 消息队列 
- 流量分发 & 负载均衡

------
# 计算机网络 BASIC

---
## 应用层
如 HTTP、FTP、Telnet、DNS、SMTP等  
只需要专注于 <b>为用户提供应用功能</b>，不用去关心数据是如何传输的  
应用层工作在操作系统中的用户态  

URL 对应于“请求某一服务器的某一资源”  
浏览器解析 URL 并生成 HTTP 消息后，委托操作系统将消息发送给 Web 服务器  

DNS服务器保存 Web 服务器域名与 IP 的对应关系  

<br>

---
### HTTP
超文本传输协议 HyperText Transfer Protocol  

HTTP/1.1：
- **持久链接（相较1.0）**：（HTTP keep-alive）使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销；可以实现管道传输（可在同一个 TCP 连接里面，客户端可以发起多个请求，不用等待响应后再发送）；但由于服务器是按请求的顺序响应的，服务器响应慢时会导致客户端一直请求不到数据（队头阻塞）
- 只能压缩`body`部分，首部信息越多延迟越大，且每次互相发送相同的首部造成的浪费较多
- 无状态：服务器不会去记忆 HTTP 的状态    
- 没有请求优先级控制
- 请求只能从客户端开始，服务器只能被动响应

Cookie：通过 在请求和响应报文中写入 Cookie 信息 来**控制客户端的状态**  

HTTP为明文传输：不安全，且无法验证身份  
HTTPS：在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，实现了信息加密和校验机制（是否被修改）、身份证书  
先TCP三次握手，在TLS四次握手  
TLS握手过程取决于 密钥交换算法  

缓存：客户端把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，形成<b>映射关系</b>，并设置一个<b>过期时间</b>；过期后发送头部带有资源摘要的请求  

HTTP/2：  
- **基于HTTPS** 先进行TCP握手，再进行TLS握手
- 头部压缩：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号；不发送同样字段，只发送索引号
- 报文采用二进制格式，以frame为最小单位（分为 headers frame 和 data frame）
- 并发传输：多个 Stream 复用在一条 TCP 连接
- 服务器推送：服务器可以主动发送消息
- 基于TCP，由于“TCP 层必须保证收到的字节数据是完整且连续的，内核才会将缓冲区里的数据返回给 HTTP 应用”，还是可能发生<b>队头阻塞</b>（有一段一直没收到）

HTTP/3:  
- **基于UDP，解决队头阻塞问题**
- 采用基于 UDP 的 QUIC 协议，实现类似 TCP 的可靠传输（QUIC上的多个流之间没有相互依赖，当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题）
- QUIC握手只需要 1 RTT（用于确认双方的「连接 ID」）（QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”）
- 在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0 RTT
- 更低的连接迁移成本（只通过连接 ID 来标记通信的两个端点）

<br>

如何减少HTTP请求次数？  
- 减少（资源迁移引起的）重定向请求次数：重定向的工作交由代理服务器完成
- 合并请求：把多个访问小文件的请求合并成一个大的请求
- 延迟发送请求：只获取当前用户所看到的页面资源

HTTP轮询：  
- 不断轮询
- 长轮询（设置较大的超时时长限制）

<br>

---
### RPC
远程过程调用 Remote Procedure Call  
像调用本地方法那样去调用远端的服务方法  
特点：面向动作、请求响应模式、同步、对象级/函数级通信  

服务发现：一般通过专门的中间服务（如 Consul 或者 Etcd）保存服务名和 IP 信息  

RPC协议一般会维护一个 <b>连接池</b>  
*请求量大时，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来*   

一般对于客户端来说，RPC是一种同步的远程服务调用技术（而MQ是异步的）  
RPC调用步骤：  
- 1、建立通信：消费者要想调用提供者的方法，首先要和提供者建立通信连接；主要是通过 客户端和服务器之间 建立TCP连接 实现的
- 2、服务寻址：确定提供者的IP、端口号以及方法的名称
- 3、网络传输：将调用方法和参数的数据进行序列化传输给提供者，提供者将接收到的参数进行反序列化操作后执行方法
- 4、服务调用：提供者进行本地调用后得到了返回值，提供者将返回值进行序列化操作后，再通过网络传输将二进制数据发送回给消费者

<br>

---
### WebSocket
利用 TCP 全双工（同一时间里，双方都可以主动向对方发送数据）  

<br>

------
## 传输层
接收方凭借传输层的报文中携带的 端口号 识别出该报文是发送给哪个应用（进程）   

序列号、确认应答号（下一个期望收到的序列号）：用于解决丢包问题  
*TCP 每次建立连接时采用不同的初始序列号，防止历史报文被下一个相同四元组的连接接收*  
校验和：用于检测包是否受损  

`MSL`：定义一个报文在网络中的最长生存时间（报文每经过一次路由器的转发，IP 头部的 `TTL` 字段就会减 1，减到 0 时报文就被丢弃）  
区别：`MSL`的单位是时间，而`TTL`是经过路由跳数；在设置时，一般认为`MSL`要大于等于`TTL`消耗为 0 的时间  

<br>

---
### TCP & UDP
在内核中实现  
TCP的机制背后是<b>通过一个个数据结构来实现的逻辑</b>。而为了实现这套逻辑，操作系统内核需要在两端代码里维护一套复杂的<b>状态机</b>（三次握手，四次挥手，RST，closing等异常处理机制），<b>这套状态机其实就是所谓的"连接"</b>。 &emsp; 而UDP不需要状态机   
（实现 **流量控制、超时重传、拥塞控制** 等 特性）  

一条 TCP 连接通过四元组（源 IP、源端口、目的 IP、目的端口）确定  
**面向连接、可靠、基于字节流**   

UDP本质是 内核提供的一个最小网络传输功能（在应用层添加可靠性保障）  

在传一个大的数据包时：  
- TCP内部根据 MSS 的大小（除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度）分段，丢包只需重传MSS分片；（使得尽量可以在TCP分片，不在IP层分片）
- 而UDP本身并不会分段，数据过大时，到了IP层进行分片，丢包需要重传整个数据包。  

TCP 面向字节流（不能认为一个用户消息对应一个 TCP 报文），UDP 面向报文（UDP 不会对消息进行拆分）  
相比 TCP 一对一，UDP 支持一对一、一对多、多对多的交互通信  

TCP粘包问题（无法确定在一个报文中的两个消息怎么划分）解决方法：使用特殊字符作为边界 或 自定义消息结构（固定长度包头 + 数据）  

TCP的不足：  
- 实现在内核中，难以更新升级
- 建立连接的延迟
- 队头阻塞
- 网络迁移需要重新建立 TCP 连接（需要通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接）

TCP和UDP可以绑定同一个端口号，TCP 和 UDP在内核中是两个完全独立的软件模块，OS 根据包头得到协议号判断为 TCP/UDP，在交由相应模块   

TCP服务端需要先进行`bind()`和`listen()`，才能接受客户端连接请求  
如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行`bind()`时会出错“Address already in use”   
（绑定IP地址不同时可以绑定同一个端口哈，但IP 0.0.0.0不行，因为这代表主机的所有IP地址）  

*只要客户端连接的服务器不同，客户端端口资源可以重复使用*  

`SO_REUSEADDR`：如果当前启动进程绑定的 IP + PORT 与处于 TIME_WAIT 状态的连接占用的 IP + PORT 存在冲突，但是新启动的进程对 socket 设置了`SO_REUSEADDR`选项，那么该进程就可以绑定成功（一般开启以实现 <b>服务端进程快速重启</b>）  

客户端在执行`connect()`函数时，会在内核里随机选择一个端口，然后向服务端发`SYN`报文进行三次握手  

服务端Linux内核在收到 TCP 报文后，会调用 `__inet_lookup_skb(...)`寻找 TCP 报文所属socket；首先查找连接建立状态的socket，未找到时，查找监听套接口（根据目的地址和目的端口算出一个哈希值，然后在 哈希表 找到对应监听该端口的 socket）；若还未找到（目标socket未处于监听状态），且收到的报文（skb）的「校验和」没问题的话，发送 RST 中止这个连接  

客户端可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开）；这两个情况都无需服务端参与（没有listen）就能建立连接，通过全局hash暂存连接信息   

TCP 负责“可靠地把数据传输到对应的缓冲区”，保证传输层的消息可靠性，但并不负责 传输层之上可能的“丢包”（如内存溢出导致程序崩溃）；若需保证，还可以引入中间服务器，让发送方和接收方定时对照消息有无缺失  

两端通信时，引入服务器还可以**减少连接数量**（只需与服务器建立连接，否则“和1000个好友聊天就得对应1000条连接”），且**方便实现各种鉴权、校验**，并可以解决**端与端之间版本不一致**的问题   

<br>

---
### TCP 三次握手与四次挥手
服务器的内核实际上为 <b>每个 TCP 的 Socket</b> 维护了 <b>两个队列</b>：（执行`listen()`方法时创建）  
- TCP 半连接队列：还没完全建立三次握手的连接（此时服务端处于 `syn_rcvd` 状态）
- TCP 全连接队列：完成了三次握手，已经建立连接的队列（此时服务端处于 `established` 状态）；这些连接等服务端执行`accept()`后被取出
- 全连接队列是一个<b>链表</b>（服务端每次直接 从队头取出）；半连接队列是一个<b>哈希表</b>（根据 第三次握手对应的IP+端口 取出）
- `tcp_syncookies`：替代半连接队列的方案，以防SYN攻击；生成一个cookie并跟随第二次握手返回，第三次握手带上这个cookie并由服务端解码验证；（缺点：编解码需要CPU资源，且攻击者可以改为伪造ACK攻击）

**三次握手**：  
1 客户端请求连接`SYN`、2 服务端回复同意`SYN + ACK`、3 客户端回复收到同意并开始正式发送数据（第三次握手可以携带数据）`ACK`  
*防止已经失效的连接请求报文突然又传送到了服务器 （阻止重复历史连接的初始化）*  
（若两次握手可能导致 因超时而重复发送的1带来了多次的连接）  

**四次挥手**（双方都要发一次`FIN`一次`ACK`）：  
1 客户端“我发完了”（但还可以接收数据）`FIN` 、2 服务端回复收到（此时服务端缓冲区可能还没read完、可能仍有数据未发送）`ACK` 、3 服务端“我发完了”`FIN` 、4 客户端回复收到`ACK`    
关键在于： 服务端通常需要等待 数据的发送和处理 全部完成   
服务端进程主动调用 `close()` 函数来触发服务端发送`FIN`报文  

当「没有数据要发送」并且「开启了 TCP 延迟确认机制」，第二和第三次挥手会合并传输  
TCP 延迟确认机制：等待一段时间或等到 有响应数据要发送 或 对方的第二个数据报文又到达 时发送`ACK`  

`ACK` 报文不会重传（需依靠前序报文的超时重传）  

**TCP 的连接信息是由内核维护的。** 当服务端的进程崩溃时，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 `FIN`报文，后续的挥手过程也都是在内核完成，并不需要进程的参与；即使服务端的进程退出了（不论是正常退出，还是异常退出（如进程崩溃）），还是能与客户端完成 TCP 四次挥手的过程  

关闭连接的函数：  
- `close()`：同时关闭 socket 发送方向和读取方向（粗暴关闭）
  - 如果有多进程/多线程共享同一个 socket，有一个进程调用`close()`关闭时，只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 `FIN` 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出`FIN`报文  
- `shutdown()`：可以指定 socket 只关闭发送方向而不关闭读取方向，socket 还可以继续接收数据（客户端一般来说调用这个！）
  - 如果有多进程/多线程共享同一个 socket，`shutdown()`则不管引用计数，直接使得该 socket 不可用，然后发出`FIN`报文

<br>

---
### TIME_WAIT
**主动发起关闭连接的一方**，才会有 TIME-WAIT 状态  
- 防止历史连接中的数据，被后面相同四元组的连接错误接收（保证再出现的数据包一定都是新建立连接所产生的，而不是在网络传输中被耽误的）（所以 快速复用参数`tcp_tw_reuse` 默认为关闭）
- 保证「被动关闭连接」的一方，能被正确的关闭

从主动方接收到`FIN`后发送`ACK`开始重置计时   
等待时间一般设置为`2MSL`（允许报文丢失一次） （*网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间*）  

服务器出现大量 TIME_WAIT 状态时，说明服务器主动断开了很多 TCP 连接  
- HTTP 没有使用长连接（在请求的header中添加 Keep-Alive）
- HTTP 长连接超时
- HTTP 长连接的请求数量达到上限

处于 TIME-WAIT 状态的连接如果收到相同四元组的`SYN`，若 序列号比服务端期望下一个收到的序列号要大 且 时间戳比服务端最后收到的报文的时间戳要大，就跳过2MSL，直接重用当前四元组连接，变为 SYN_RECV 状态  

<br>

---
### TCP 序列号 & 确认号
序列号：用以解决网络包乱序问题。在建立连接时由 内核生成的随机数 作为其初始值，通过`SYN`报文传给接收端主机；每发送一次数据，就「累加」一次该「数据字节数」的大小（建立连接or断开连接时为 1）
（客户端和服务端分别有初始的序列号）  
确认号：用来解决丢包问题。下一次「期望收到的数据的序列号」；可以认为在这个序号以前的数据都已经被正常接收  

序列号 = 上一次发送的序列号 + len（数据长度）  
确认号 = 上一次收到的报文中的序列号 + len（数据长度）  

<br>

---
### TCP 重传机制
超时重传  

快速重传：发送端接收到连续的三个重复冗余ACK   

---
### TCP 滑动窗口
提升了发送速度，同时兼顾了接收方的处理能力  
让发送方根据接收方的实际接收能力控制发送的数据量  

报文存放在OS的内核缓冲区  
发送缓冲区大小决定了 <b>发送窗口</b> 的上限，而发送窗口又决定了 “已发送未确认” 的报文的上限  
发送缓冲区不能超过 带宽时延积（RTT * 带宽）  

接收方把 当前 <b>接收窗口</b> 可接收的大小 放在 TCP 报文头部中的窗口字段  

发送缓冲区是自行调节的；当数据被确认后，且没有新的数据要发送，就会把发送缓冲区的内存释放掉  
接收缓冲区可以根据系统空闲内存的大小来调节接收窗口  

在发送端调用`send`，只是从应用程序拷贝到操作系统的内核协议栈中，还没有真正地发出  

<br>

---
### TCP 异常状况
客户端进程崩溃：  
内核回收资源；内核会发送`FIN`报文，与服务端进行四次挥手   

客户端宕机：  
只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复`RST`报文，以断开连接   
若客户端一直没有重启，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开；如果服务端没有开启 keep-alive，又没有发送数据，会一直处于 ESTABLISHED 连接状态   

<br>

---
### TCP 流量控制
让「发送方」根据「接收方」的实际接收能力控制发送的数据量  
TCP 通过让接收方指明 **希望从发送方接收的数据大小（窗口大小）** 来进行流量控制   

TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，以防止丢包  

只要 TCP 连接一方收到对方的零窗口通知，就 <b>启动持续计时器</b>；一段时间后发送 <b>窗口探测报文</b>  

<br>

---
### TCP 拥塞控制
在网络拥堵时，控制发送流量，避免「发送方」的数据填满整个网络  
发生超时重传时，认为网络出现了拥塞   

发送窗口`swnd`是 **拥塞窗口`cwnd`和接收窗口`rwnd`中的最小值**  

主要策略：
- 慢启动：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1（`cwnd < ssthresh`时，使用慢启动算法）
- 拥塞避免算法：每当收到一个 ACK 时，cwnd 增加 1/cwnd（`cwnd` >= `ssthresh` 时，就会使用拥塞避免算法）
- 超时重传时，`ssthresh`设为`cwnd/2`，`cwnd`重置为`1`
- 快速重传时，`cwnd`设为`cwnd/2`，`ssthresh`设为`cwnd`

<br>

---
### 如何基于 UDP 实现可靠传输？
把 TCP 可靠传输的特性（序列号、确认应答、超时重传、流量控制、拥塞控制）在应用层实现一遍  
QUIC 协议  
QUIC 中报文号严格递增，没有重传歧义问题，且支持乱序确认  
通过 Stream ID + Offset 字段信息判断数据包，实现数据的有序性  

QUIC 为连接内的每一个 Stream 都分配了一个独立的滑动窗口  

<br>

------
## 网络层
寻路、路由；负责将数据从一个设备传输到另一个设备（路径和节点选择）  

### IP协议
将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文   
MTU：数据链路的最大传输单元  
经过分片之后的 IP 数据报的重组时只由目标主机进行，路由器不会进行重组   
（TCP引入了 MSS 以在TCP层分片，避免在IP层分片；UDP尽量不要传大于MTU的报文）  

IP 地址分成两种意义：（通过子网掩码）
- 网络号：负责标识该 IP 地址是属于哪个「子网」的；
- 主机号：负责标识同一「子网」下的不同主机；

IPv4 地址长度共`32`位，以每 8 位作为一组，用点分十进制的表示方式  
IPv6 地址长度是`128`位，以每 16 位作为一组，每组用冒号 「:」 隔开（`::`表示连续的 0）（更多的地址、更好的安全性和扩展性）   

CIDR：将地址划分为 网络号+主机号  

<br>

### DNS
将域名网址自动转换为具体的 IP 地址  

根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中   
客户端只要能够找到任意一台 DNS 服务器（先找本地 DNS 服务器），就可以通过它找到根域 DNS 服务器，然后再一路找到位于下层的某台目标 DNS 服务器  

<br>

### ARP 
ARP协议用于获取下一跳的 MAC 地址  
主机通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机对应的 IP 地址  
同个链路中的所有设备收到 ARP 请求时，如果 请求包中的目标 IP 地址与自己的一致，就将自己的 MAC 地址塞入 ARP 响应包 返回给源主机  

操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下一次直接从缓存中查找  

RARP协议：已知MAC地址，获取IP地址  

<br>

### DHCP
通过 DHCP 动态获取 IP 地址：  
- 客户端首先发起 DHCP 发现报文（`DHCP DISCOVER`）：使用 UDP 广播通信；广播目的地址是 `255.255.255.255（端口 67）`，并使用`0.0.0.0（端口 68）`作为源 IP 地址）
- DHCP 服务器收到 DHCP 发现报文时，响应 DHCP 提供报文（`DHCP OFFER`）；该报文仍然使用 IP 广播地址`255.255.255.255`，携带 服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期
- 客户端收到一个或多个服务器的 DHCP 提供报文后，选择一个服务器，发送 DHCP 请求报文（`DHCP REQUEST`）进行响应
- 最后，服务端用`DHCP ACK`报文对 DHCP 请求报文进行响应，应答所要求的参数
- 租约的 DHCP IP 地址快期后，客户端会再向服务器发送 DHCP 请求报文

DHCP中继代理：收到这个广播包以后，再以单播的形式发给 DHCP 服务器（以跨越不同局域网）  

<br>

### NAT
缓解IPv4地址耗尽的问题  
同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址  
生成一个 NAPT 路由器的转换表；映射到相同IP时，用端口号做区分  

NAT的问题：  
- 外部无法主动与NAT内部服务器建立连接，因为NAPT转换表没有转换记录
- 转换表的生成与转换操作都会产生性能开销
- 通信过程中，如果NAT路由器重启了，所有的TCP连接都将被重置

NAT穿透技术：客户端主动从NAT设备获取公有IP地址，建立端口映射条目，此后用这个条目对外通信，不需要NAT设备来进行转换   

<br>

### ICMP
Internet Control Message Protocol 互联网控制报文协议  
确认 IP包是否成功送达目标地址、报告发送过程中 IP包被废弃的原因 和 改善网络设置等  
*在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，这个具体的原因将由 ICMP 负责通知*  

ICMP 类型：
- 用于诊断的查询消息 <b>查询报文类型</b>
  - 如`ping`发送 回送请求消息，接受目标端主机发送的 回送应答消息；用标识符区分是哪个应用程序发的ICMP包，并携带从`0`开始，每次发送`+1`的序列号，以确认网络包是否有丢失
- 通知出错原因的错误消息 <b>差错报文类型</b>
  - 目标不可达：（内容代码：）网络不可达、主机不可达、协议不可达、端口不可达、需要分片但设置了不分片
  - 原点抑制消息：解决网络拥堵问题；路由器向低速线路发送数据的场景，其发送队列的缓存变为零而无法发送出去时，向 IP 包的源地址发 ICMP 原点抑制消息
  - 重定向消息：路由器发现发送端主机使用了「不是最优」的路径发送数据
  - 超时消息：TTL 减至`0`时，避免 IP 包无休止地在网络上被转发

<br>

### IGMP
因特网组管理协议；工作在主机（组播成员）和最后一跳路由之间  
IGMP 报文向路由器 申请加入和退出组播组  

<br>

### 路由控制
IP的网络地址用于路由控制  
路由控制表中记录着网络地址与下一步应该发送至路由器的地址，遵循最长匹配  

------
# 消息队列 MQ
特点：面向数据、生产者与消费者、有缓冲节点、异步、系统级/模块级通信  
主要应用场景：延时任务、应用解耦（MQ负责通知，各节点对应于消息作不同操作）、流量削峰、日志处理（日志处理应用订阅并削峰消息队列中的日志数据，避免短期要处理大量日志）、异步消息通讯（提供系统整体吞吐量）

消息的发送者和消费者不再直接交互，而是通过中间件间接交互，实现了解耦  
发送者并不关心谁来消费信息（常常不止一个消费者）；且各个消费者可以从不同的角度入手处理消息，处理结果也不用返回给发送者    

- 点对点模式：一个生产者发送的每一个消息，都只有一个消费者消费；允许多个生产者向同一个队列里发送消息，但是只有一个消费者能拿到数据
- 发布订阅模式：消息会发送到所有订阅了此队列的消费者；一个队列为一个“主题”

---
## Kafka
利用了「零拷贝」技术，大幅提升了 I/O 吞吐率（只需要 2 次上下文切换和数据拷贝次数）  
没有在内存层面拷贝数据（全程没有通过 CPU 来搬运数据，所有数据通过 DMA 来进行传输）　　

------
# 流量分发 & 负载均衡
如何分配客户端的请求？  

------
### 一致性哈希
避免分布式系统在扩容或者缩容（节点数量变化）时，由于哈希值变化（映射关系改变），发生过多的数据迁移  

一致性哈希：将「存储节点」和「数据」都映射到一个首尾相连的哈希环上  
在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点   

一致性哈希算法虽然减少了数据迁移量，但存在节点分布不均匀的问题  
解决办法：加入虚拟节点；不再将真实节点映射到哈希环上，而是**将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点**（两层映射关系）  

<br>

---
## Nginx
